# üöÄ Distributed Deep Learning Pipeline with Kubernetes & PyTorch

[![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=flat&logo=kubernetes&logoColor=white)](https://kubernetes.io/)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![MinIO](https://img.shields.io/badge/MinIO-C72E49?style=flat&logo=minio&logoColor=white)](https://min.io/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

> Pipeline MLOps end-to-end pour l'entra√Ænement distribu√© de ResNet-18 sur CIFAR-10 avec Kubernetes, PyTorchJob et MinIO.

---

## üìã Table des Mati√®res

- [Vue d'Ensemble](#-vue-densemble)
- [Architecture](#-architecture)
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Pr√©requis](#-pr√©requis)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Pipeline MLOps](#-pipeline-mlops)
- [R√©sultats](#-r√©sultats)
- [Monitoring](#-monitoring)
- [D√©ploiement](#-d√©ploiement)
- [Troubleshooting](#-troubleshooting)
- [Contributeurs](#-contributeurs)

---

## üéØ Vue d'Ensemble

Ce projet impl√©mente un **pipeline MLOps complet** pour l'entra√Ænement distribu√© de r√©seaux de neurones profonds sur Kubernetes. Il d√©montre les meilleures pratiques de l'industrie pour le Machine Learning en production :

- ‚úÖ **Distributed Training** : Entra√Ænement parall√®le avec PyTorch DDP
- ‚úÖ **Container Orchestration** : D√©ploiement et scaling avec Kubernetes
- ‚úÖ **Artifact Management** : Versioning des mod√®les avec MinIO (S3-compatible)
- ‚úÖ **Reproducibility** : Pipeline automatis√© et reproductible
- ‚úÖ **Production-Ready** : Architecture scalable et d√©ployable

### üéì Cas d'Usage

- Entra√Ænement de mod√®les de vision par ordinateur √† grande √©chelle
- MLOps dans des environnements √† ressources limit√©es
- Prototype de pipeline de production pour startups/PME
- Projet acad√©mique de Deep Learning distribu√©

---

## üèóÔ∏è Architecture

![Architecture globale](images/Architecture.png)

### üîß Technologies Utilis√©es

| Composant | Technologie | Version | R√¥le |
|-----------|------------|---------|------|
| **Orchestration** | Kubernetes | 1.34+ | Gestion des conteneurs |
| **Cluster** | Minikube | 1.37+ | Cluster Kubernetes local |
| **Training Framework** | PyTorch | 2.0.0 | Deep Learning |
| **Distributed Training** | PyTorch DDP | - | Parall√©lisation |
| **Job Operator** | Kubeflow Training Operator | 1.8.1 | Gestion PyTorchJob |
| **Storage** | MinIO | 2023-09 | Object storage (S3) |
| **Dataset** | CIFAR-10 | - | 60K images 32x32 |
| **Model** | ResNet-18 | - | CNN (11M params) |

---

## ‚ú® Fonctionnalit√©s

### üéØ Pipeline MLOps Complet

1. **Data Ingestion**
   - T√©l√©chargement automatique de CIFAR-10
   - Sauvegarde dans MinIO pour r√©utilisation
   - Support de datasets personnalis√©s

2. **Feature Engineering**
   - Data augmentation (flip, crop)
   - Normalisation selon statistiques CIFAR-10
   - Distribution intelligente des donn√©es entre workers

3. **Distributed Training**
   - PyTorch Distributed Data Parallel (DDP)
   - Communication backend : Gloo (CPU-optimized)
   - Synchronisation automatique des gradients
   - 1 Master + 1 Worker (extensible √† N workers)

4. **Model Evaluation**
   - M√©triques calcul√©es √† chaque epoch
   - Train accuracy, Test accuracy
   - Train loss, Test loss

5. **Model Versioning**
   - Checkpoints sauvegard√©s √† chaque epoch
   - Versioning avec timestamps
   - Mod√®le "latest" toujours disponible

6. **Automated Deployment**
   - Mod√®les pr√™ts pour d√©ploiement
   - API REST pour inf√©rence (optionnel)

### üöÄ Optimisations

- **Efficacit√© m√©moire** : Batch size optimis√©, gradient accumulation
- **Vitesse** : DataLoader multi-threaded, pin_memory
- **Robustesse** : Gestion d'erreurs, retry automatique
- **Observabilit√©** : Logs d√©taill√©s, m√©triques structur√©es

---

## üì¶ Pr√©requis

### Syst√®me d'Exploitation

- **Windows** : Windows 10/11 avec WSL2
- **Linux** : Ubuntu 20.04+ ou √©quivalent
- **macOS** : macOS 11+ avec Docker Desktop

### Ressources Mat√©rielles

| Composant | Minimum | Recommand√© |
|-----------|---------|------------|
| **CPU** | 2 cores | 4 cores |
| **RAM** | 6 GB | 8 GB |
| **Disque** | 20 GB | 30 GB |
| **GPU** | Optionnel | Optionnel |

### Logiciels

- Docker 20.10+
- Kubernetes (via Minikube)
- Python 3.9+
- Git

---

## üîß Installation

### √âtape 1 : Environnement de Base

#### Sur Windows (WSL2)

```powershell
# Dans PowerShell en Administrateur
wsl --install
# Red√©marrer Windows
```

Puis dans WSL2 Ubuntu :

```bash
# Mise √† jour syst√®me
sudo apt update && sudo apt upgrade -y

# Installation Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# Fermer et rouvrir WSL pour appliquer les changements
exit
# Puis rouvrir WSL
```

#### Sur Linux

```bash
# Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER
newgrp docker

# V√©rifier
docker --version
```

### √âtape 2 : Kubernetes (Minikube)

```bash
# T√©l√©charger Minikube
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# Installer kubectl
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install kubectl /usr/local/bin/

# V√©rifier les installations
minikube version
kubectl version --client
```

### √âtape 3 : D√©marrage du Cluster

```bash
# Cr√©er un cluster Kubernetes local
minikube start --cpus=2 --memory=6144 --disk-size=20g --driver=docker

# V√©rifier que le cluster fonctionne
kubectl cluster-info
kubectl get nodes
```

**Sortie attendue** :
```
NAME       STATUS   ROLES           AGE   VERSION
minikube   Ready    control-plane   1m    v1.34.0
```

### √âtape 4 : Kubeflow Training Operator

```bash
# Cloner le repository
git clone --depth 1 --branch v1.8.1 https://github.com/kubeflow/training-operator.git
cd training-operator

# Installer l'op√©rateur
kubectl apply -k manifests/overlays/standalone

# Attendre que ce soit pr√™t
kubectl wait --for=condition=ready pod -l app=training-operator -n kubeflow --timeout=300s

# V√©rifier
kubectl get pods -n kubeflow
```

**Sortie attendue** :
```
NAME                                 READY   STATUS    RESTARTS   AGE
training-operator-xxxxx-xxxxx        1/1     Running   0          1m
```

### √âtape 5 : D√©pendances Python

```bash
# Cr√©er un environnement virtuel
cd ~
mkdir mlops-distributed-project
cd mlops-distributed-project

python3 -m venv venv
source venv/bin/activate

# Installer les packages
pip install --upgrade pip
pip install torch torchvision minio requests pillow
```

---

## üöÄ Utilisation

### Cloner le Projet

```bash
cd ~/mlops-distributed-project

# Si vous avez un repository Git
git clone <votre-repo-url> .

# OU cr√©er les fichiers manuellement (voir ci-dessous)
```

### Cr√©er les Fichiers de Configuration

#### Fichier 1 : `lightweight-pipeline.yaml`

```bash
nano lightweight-pipeline.yaml
```

Copiez le contenu complet du pipeline (voir [lightweight-pipeline.yaml](./lightweight-pipeline.yaml)).

**Points cl√©s du fichier** :
- Namespace `mlops-light`
- D√©ploiement MinIO
- ConfigMap avec le code d'entra√Ænement
- PyTorchJob avec Master + Worker
- Ressources CPU/M√©moire optimis√©es

#### Fichier 2 : `quick-run.sh`

```bash
nano quick-run.sh
chmod +x quick-run.sh
```

Copiez le contenu du script de lancement (voir [quick-run.sh](./quick-run.sh)).

### Lancer le Pipeline

```bash
# Tout en une commande
./quick-run.sh
```

**Ce script va** :
1. ‚úÖ Nettoyer les namespaces pr√©c√©dents
2. ‚úÖ D√©ployer MinIO
3. ‚úÖ Cr√©er les buckets n√©cessaires
4. ‚úÖ Lancer le PyTorchJob distribu√©
5. ‚úÖ Afficher les logs en temps r√©el

### Sortie Attendue

```
==========================================
  Version ALL√âG√âE - Sans MLflow
  Uniquement: MinIO + PyTorchJob
==========================================

[1/5] Nettoyage...
namespace "mlops-light" deleted

[2/5] D√©ploiement de l'infrastructure...
namespace/mlops-light created
deployment.apps/minio created
service/minio created
pytorchjob.kubeflow.org/resnet-light created

[3/5] Attente de MinIO...
pod/minio-xxxxx condition met

[4/5] Configuration des buckets MinIO...
‚úì Bucket 'datasets' cr√©√©
‚úì Bucket 'models' cr√©√©
‚úì Bucket 'metrics' cr√©√©

[5/5] Lancement de l'entra√Ænement distribu√©...
Logs en temps r√©el:
[Rank 0/2] üöÄ D√âMARRAGE ENTRA√éNEMENT DISTRIBU√â
...
```

---

## üìä Pipeline MLOps

Le pipeline est compos√© de **5 √©tapes principales** :

### 1Ô∏è‚É£ Data Ingestion

```python
# T√©l√©chargement automatique de CIFAR-10
trainset = torchvision.datasets.CIFAR10(
    root='/data', train=True, download=True, transform=transform_train
)
testset = torchvision.datasets.CIFAR10(
    root='/data', train=False, download=True, transform=transform_test
)
```

**R√©sultat** : 50,000 images d'entra√Ænement + 10,000 images de test

### 2Ô∏è‚É£ Feature Engineering

```python
# Transformations et augmentation
transform_train = transforms.Compose([
    transforms.RandomHorizontalFlip(),      # Flip horizontal al√©atoire
    transforms.RandomCrop(32, padding=4),    # Crop al√©atoire
    transforms.ToTensor(),                   # Conversion en tenseur
    transforms.Normalize((0.4914, 0.4822, 0.4465), 
                         (0.2023, 0.1994, 0.2010))  # Normalisation
])
```

**R√©sultat** : DataLoaders configur√©s avec DistributedSampler

### 3Ô∏è‚É£ Distributed Training

```python
# Configuration du training distribu√©
if world_size > 1:
    dist.init_process_group(backend='gloo', ...)
    model = DDP(model)

# Entra√Ænement sur 10 epochs
for epoch in range(10):
    # Training loop avec synchronisation automatique
    ...
```

**Strat√©gie** : 
- PyTorch Distributed Data Parallel (DDP)
- Backend Gloo (optimis√© CPU)
- Synchronisation des gradients automatique

### 4Ô∏è‚É£ Model Evaluation

```python
# √âvaluation √† chaque epoch
model.eval()
with torch.no_grad():
    for inputs, targets in testloader:
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        # Calcul accuracy
        ...
```

**M√©triques calcul√©es** :
- Train Loss & Accuracy
- Test Loss & Accuracy

### 5Ô∏è‚É£ Model Versioning

```python
# Sauvegarde avec timestamp
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# Checkpoint √† chaque epoch
torch.save(checkpoint, f'/output/checkpoint_epoch_{epoch+1}.pth')

# Upload vers MinIO
minio_client.fput_object(
    "models",
    f"resnet-cifar10/model_v{timestamp}.pth",
    final_model_path
)
```

**Organisation MinIO** :
```
models/
‚îî‚îÄ‚îÄ resnet-cifar10/
    ‚îú‚îÄ‚îÄ checkpoint_epoch_1.pth
    ‚îú‚îÄ‚îÄ checkpoint_epoch_2.pth
    ‚îú‚îÄ‚îÄ ...
    ‚îú‚îÄ‚îÄ checkpoint_epoch_10.pth
    ‚îú‚îÄ‚îÄ model_v20241228_143022.pth
    ‚îî‚îÄ‚îÄ model_latest.pth

metrics/
‚îî‚îÄ‚îÄ resnet-cifar10/
    ‚îî‚îÄ‚îÄ metrics_v20241228_143022.json
```

---

## üìà R√©sultats

### M√©triques de Performance

**Configuration** :
- Mod√®le : ResNet-18 (11M param√®tres)
- Dataset : CIFAR-10 (60K images)
- Epochs : 10
- Batch Size : 128
- Learning Rate : 0.1 (avec cosine annealing)
- Optimizer : SGD (momentum=0.9, weight_decay=5e-4)
- Workers : 1 Master + 1 Worker

**R√©sultats Attendus** :

| Epoch | Train Loss | Train Acc | Test Loss | Test Acc |
|-------|------------|-----------|-----------|----------|
| 1 | 2.168 | 29.70% | 1.63 | 39.00% |
| 2 | 1.512 | 45.6% | 1.398 | 50.2% |
| 5 | 1.058 | 62.06% | 1.025 | 63.32% |
| 10 | 0.421 | 73.43% | 0.748 | 78.5% |

**Graphiques** :

![Train vs Test Accuracy](images/metrics.png)


### Temps d'Ex√©cution

| Phase | Dur√©e | Description |
|-------|-------|-------------|
| Setup | 2-3 min | D√©ploiement MinIO, cr√©ation buckets |
| Data Download | 1-2 min | CIFAR-10 download (premi√®re fois) |
| Training | 4‚Äì5 h | 10 epochs complets |
| Saving | 1-2 min | Upload vers MinIO |
| **Total** | **4h :4min‚Äì 5h :7min** | Pipeline complet |

### Utilisation Ressources

```bash
# Pendant l'entra√Ænement
kubectl top nodes
kubectl top pods -n mlops-light
```

---

## üîç Monitoring

### Surveiller l'Entra√Ænement

#### 1. Status du PyTorchJob

```bash
kubectl get pytorchjob -n mlops-light
```

**Sortie** :
```
NAME           STATE       AGE
resnet-light   Running     15m
```

**√âtats possibles** :
- `Created` : Job cr√©√©, pods en cours de d√©marrage
- `Running` : Entra√Ænement en cours
- `Succeeded` : Entra√Ænement termin√© avec succ√®s
- `Failed` : √âchec de l'entra√Ænement

#### 2. Pods d'Entra√Ænement

```bash
kubectl get pods -n mlops-light
```

**Sortie** :
```
NAME                      READY   STATUS    RESTARTS   AGE
minio-xxxxx               1/1     Running   0          20m
resnet-light-master-0     1/1     Running   0          18m
resnet-light-worker-0     1/1     Running   0          18m
```

#### 3. Logs en Temps R√©el

**Master (Rank 0)** :
```bash
kubectl logs -f -l training.kubeflow.org/job-name=resnet-light,training.kubeflow.org/replica-type=master -n mlops-light
```

**Worker (Rank 1)** :
```bash
kubectl logs -f -l training.kubeflow.org/job-name=resnet-light,training.kubeflow.org/replica-type=worker -n mlops-light
```

**Exemple de logs** :
```
============================================================
[Rank 0/2] üöÄ D√âMARRAGE ENTRA√éNEMENT DISTRIBU√â
============================================================

[Rank 0] üì• √âTAPE 1/5: Data Ingestion
[Rank 0] ‚úì 50000 train, 10000 test

[Rank 0] üîß √âTAPE 2/5: Feature Engineering
[Rank 0] ‚úì DataLoaders configur√©s

[Rank 0] üèóÔ∏è  √âTAPE 3/5: Model Creation
[Rank 0] ‚úì ResNet-18 cr√©√©

[Rank 0] üéØ Entra√Ænement 10 epochs...

  Epoch 1/10 [0/391] Loss: 2.303 Acc: 9.38%
  Epoch 1/10 [50/391] Loss: 2.156 Acc: 18.75%
  ...
```

### Acc√©der √† MinIO Console

```bash
# Port-forwarding
kubectl port-forward -n mlops-light svc/minio 9001:9001
```

Puis ouvrir dans le navigateur : **http://localhost:9001**

**Credentials** :
- Username : `minioadmin`
- Password : `minioadmin`

**Navigation** :
1. Cliquer sur "Buckets"
2. S√©lectionner `models`
3. Naviguer dans `resnet-cifar10/`
4. T√©l√©charger les checkpoints et m√©triques

### Visualiser les M√©triques

```bash
# T√©l√©charger les m√©triques
kubectl port-forward -n mlops-light svc/minio 9000:9000 &

![Train vs Test Accuracy](images/minio-metrics.png)

---

## üöÄ D√©ploiement

### D√©ployer le Mod√®le pour Inf√©rence

Une fois l'entra√Ænement termin√©, d√©ployez une API REST pour faire des pr√©dictions.

#### Cr√©er le Service d'Inf√©rence

```bash
nano deploy-inference.yaml
```
Puis copier le contenu complet du fichier deploy-inference.yaml


#### D√©ployer

```bash
kubectl apply -f deploy-inference.yaml

# Attendre que le pod soit pr√™t
kubectl wait --for=condition=ready pod -l app=inference -n mlops-light --timeout=300s
```

#### Tester l'API

```bash
# Port-forward
kubectl port-forward -n mlops-light svc/inference 8080:8080 &

# Test avec une image
curl -X POST -F "file=@test_image.png" http://localhost:8080/predict
```

**R√©ponse attendue** :
```json
{
  "prediction": "cat",
  "confidence": 0.9234
}
```

---

## Authors 
- Ezzahra Ait El Arbi  
- Zahira El Aamrani  
- Hafssa Errami  

Supervisor: *Fahd Kalloubi*  
Faculty of Sciences Semlalia, Cadi Ayyad University, Marrakech

---
---

## üõ†Ô∏è Troubleshooting

### Probl√®mes Courants

#### 1. Pods en `Pending`

**Sympt√¥me** :
```bash
kubectl get pods -n mlops-light
# resnet-light-master-0   0/1   Pending   0   5m
```

**Cause** : Ressources insuffisantes

**Solution** :
```bash
# Supprimer et recr√©er Minikube avec plus de m√©moire
minikube delete
minikube start --cpus=2 --memory=8192 --disk-size=20g --driver=docker
```

#### 2. `ImagePullBackOff`

**Sympt√¥me** :
```bash
kubectl describe pod -n mlops-light resnet-light-master-0
# Warning  Failed  ... Failed to pull image "pytorch/pytorch:2.0.0"
```

**Cause** : Probl√®me r√©seau ou image inexistante

**Solution** :
```bash
# V√©rifier la connexion
docker pull pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime

# Si √ßa √©choue, utiliser une image plus l√©g√®re
# √âditer lightweight-pipeline.yaml :
# image: pytorch/pytorch:2.0.0-cpu
```

#### 3. Pods en `CrashLoopBackOff`

**Sympt√¥me** :
```bash
kubectl get pods -n mlops-light
# resnet-light-master-0   0/1   CrashLoopBackOff   3   5m
```

**Solution** :
```bash
# Voir les logs d'erreur
kubectl logs -n mlops-light resnet-light-master-0

# Probl√®mes courants :
# - Erreur Python ‚Üí V√©rifier le code dans le ConfigMap
# - Erreur MinIO ‚Üí V√©rifier que MinIO est Running
# - OOMKilled ‚Üí Augmenter les ressources m√©moire
```

#### 4. MinIO Inaccessible

**Sympt√¥me** :
```
‚ö†Ô∏è  MinIO: connection refused
```

**Solution** :
```bash
# V√©rifier MinIO
kubectl get pods -n mlops-light -l app=minio

# Red√©marrer MinIO
kubectl rollout restart deployment minio -n mlops-light

# Attendre
kubectl wait --for=condition=ready pod -l app=minio -n mlops-light --timeout=120s
```

#### 5. Training Operator Non Install√©

**Sympt√¥me** :
```
error: unable to recognize "lightweight-pipeline.yaml": 
no matches for kind "PyTorchJob"
```

**Solution** :
```bash
# V√©rifier l'installation
kubectl get pods -n kubeflow

# Si absent, r√©installer
cd ~/mlops-distributed-project/training-operator
kubectl apply -k manif